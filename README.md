# Forecasting Skin Lesion Progression (T1, T2 â†’ T3) with Swinâ€‘UNet + CBAM & PatchGAN

> Predict the **future state of a skin lesion (T3)** from two prior snapshots **T1 & T2**, using a GAN-based dualâ€‘input generator for sharper, more realistic forecasts.

---

## âœ¨ Highlights

* **Task**: Forecast T3 image from T1 and T2 lesion images (progression modeling).
* **Approach**: **GAN** with **Swinâ€‘UNet + CBAM** generator and **PatchGAN** discriminator.
* **Losses**: Adversarial + **Perceptual (VGG19 features)** + **L1**.
* **Metrics**: **MSE, MAE, SSIM, PSNR**, plus optional perceptual similarity.
* **Baselines**: Nonâ€‘GAN Uâ€‘Net/Swinâ€‘UNet regression model (L1 + Perceptual) for ablations.
* **Extras**: Training curves, Gradâ€‘CAM/attention maps (optional), Streamlit demo app.

---

## ğŸ“· Problem Statement

Given two timeâ€‘stamped lesion images **T1** and **T2** of the same lesion, generate a realistic forecast **T3** that preserves lesion morphology and texture evolution (e.g., spread, boundary sharpness, redness).

---

## ğŸ§  Method Overview

### Generator (G): Swinâ€‘UNet + CBAM (Dualâ€‘Input)

* **Inputs**: Concatenated channels `[T1, T2]` (e.g., 2Ã—(HÃ—WÃ—1/3)).
* **Backbone**: Swin Transformer Uâ€‘Net encoderâ€‘decoder for multiâ€‘scale context.
* **Attention**: **CBAM** (Channel & Spatial) in skip connections for feature refinement.
* **Output**: Predicted **T3** image (same size as inputs).

### Discriminator (D): PatchGAN

* Operates on local patches (â‰ˆ70Ã—70) for fineâ€‘grained realism judgment.
* Inputs are pairs `(T1,T2,T3)` â†’ real vs `(T1,T2,G(T1,T2))` â†’ fake.

### Losses

* **Adversarial**: PatchGAN (LSGAN/BCE) on Dâ€™s real/fake classification.
* **Perceptual Loss**: `L_perc = Î£_i || Ï•_i(T3) âˆ’ Ï•_i(G(T1,T2)) ||_1`, where Ï•\_i are VGG19 feature maps.
* **Pixel Loss**: `L_L1 = || T3 âˆ’ G(T1,T2) ||_1`.
* **Total**: `L_G = Î»_adv L_adv + Î»_perc L_perc + Î»_L1 L_L1` (defaults: 1.0 / 1.0 / 100.0).

---

## ğŸ—‚ï¸ Dataset Structure

Organize your dataset as follows (example):

```
DATA_ROOT/
  lesions/
    lesion_001/
      T1.png
      T2.png
      T3.png
    lesion_002/
      T1.png
      T2.png
      T3.png
  splits/
    train.txt   # list of lesion IDs for training
    val.txt     # list of lesion IDs for validation
    test.txt    # list of lesion IDs for testing
```

**Notes**

* Images are resized/cropped to **256Ã—256** (configurable) and normalized to **\[-1, 1]**.
* If your data are RGB, keep channels asâ€‘is; for grayscale, use 1 channel.
* Ensure T1/T2/T3 for a lesion are **aligned and patientâ€‘consistent**.

---

## ğŸ› ï¸ Installation

### 1) Create environment

```bash
conda create -n lesion-forecast python=3.10 -y
conda activate lesion-forecast
```

### 2) Install requirements

```bash
pip install -r requirements.txt
```

`requirements.txt` (reference):

```
tensorflow>=2.12
tensorflow-addons
opencv-python
scikit-image
pillow
numpy
pandas
matplotlib
albumentations
scikit-learn
tqdm
```

> âœ… GPU recommended. Install a TF build matching your CUDA/CuDNN versions if needed.



## ğŸš€ Quick Start

### 1) Prepare data

Update `configs/base.yaml` paths, or pass via CLI.

### 2) Train (GAN)

```bash
python training/train_gan.py \
  --data_root /path/to/DATA_ROOT \
  --img_size 256 \
  --batch_size 4 \
  --epochs 200 \
  --lambda_perc 1.0 \
  --lambda_l1 100.0 \
  --g_lr 2e-4 --d_lr 2e-4 \
  --out_dir experiments/runs/gan_swin_cbam
```

### 3) Train (Baseline)

```bash
python training/train_baseline.py \
  --data_root /path/to/DATA_ROOT \
  --img_size 256 \
  --batch_size 8 \
  --epochs 150 \
  --lambda_perc 1.0 --lambda_l1 100.0 \
  --out_dir experiments/runs/baseline_swin
```

### 4) Inference

```bash
python inference/predict.py \
  --data_root /path/to/DATA_ROOT \
  --checkpoint experiments/runs/gan_swin_cbam/best.ckpt \
  --save_dir outputs/predictions
```

### 5) Streamlit Demo

```bash
streamlit run app/streamlit_app.py \
  -- --checkpoint experiments/runs/gan_swin_cbam/best.ckpt \
  --img_size 256
```

---

## ğŸ“Š Evaluation

Run evaluation on the test split:

```bash
python inference/visualize.py \
  --data_root /path/to/DATA_ROOT \
  --pred_dir outputs/predictions \
  --metrics mse mae ssim psnr \
  --save_report outputs/metrics.csv
```

**Metrics Tracked**

* **MSE**: Mean Squared Error
* **MAE**: Mean Absolute Error
* **SSIM**: Structural Similarity Index
* **PSNR**: Peak Signalâ€‘toâ€‘Noise Ratio
* **Perceptual loss** (report only): average VGG feature L1

Example (placeholder) results table:

|                                 Model |     MSE â†“ |     MAE â†“ |    SSIM â†‘ |   PSNR â†‘ |
| ------------------------------------: | --------: | --------: | --------: | -------: |
|                  Baseline (Swinâ€‘UNet) |     0.012 |     0.067 |     0.812 |     25.8 |
| **GAN (Swinâ€‘UNet + CBAM + PatchGAN)** | **0.010** | **0.061** | **0.835** | **26.6** |

> Replace with your actual numbers after training; CSV export is enabled.

---

## ğŸ§ª Ablations & Visuals

* **Ablations**: remove CBAM, change loss weights, swap Swinâ€‘UNet â†’ Uâ€‘Net.
* **Qualitative**: grids of `[T1, T2, GT(T3), Pred(T3)]` with SSIM/PSNR overlays.
* **Attention/Gradâ€‘CAM**: visualize attention maps to interpret lesion focus.

---

## âš™ï¸ Configs (YAML)

Key flags in `configs/base.yaml`:

```yaml
img_size: 256
batch_size: 4
epochs: 200
lambda_adv: 1.0
lambda_perc: 1.0
lambda_l1: 100.0
g_lr: 0.0002
d_lr: 0.0002
norm: instance  # or batch
optimizer: adam
mixed_precision: true
```

---

## ğŸ§® Math Summary

Given inputs **xâ‚ = T1**, **xâ‚‚ = T2**, and target **y = T3**:

* **G** predicts **Å· = G(xâ‚, xâ‚‚)**.
* **Adversarial loss (LSGAN)**: $L_{adv} = \mathbb{E}[(D(x, y) - 1)^2] + \mathbb{E}[D(x, Å·)^2]$.
* **Perceptual loss**: $L_{perc} = \sum_i \| \phi_i(y) - \phi_i(Å·) \|_1$.
* **Pixel loss**: $L_{L1} = \| y - Å· \|_1$.
* **Total**: $L_G = \lambda_{adv} L_{adv} + \lambda_{perc} L_{perc} + \lambda_{L1} L_{L1}$.

---

## ğŸ” Reproducibility

* **Seeds**: set `--seed 42` for determinism.
* **Checkpoints**: saved every N epochs; `best.ckpt` by val SSIM.
* **Logging**: TensorBoard under `experiments/runs/*/logs`.

---

## ğŸ“ˆ Roadmap

* [ ] Add multiâ€‘task heads (segmentation, redness score)
* [ ] Temporal consistency loss (optical flow / warping)
* [ ] Selfâ€‘distillation for fewâ€‘shot lesions
* [ ] Model quantization for edge devices
* [ ] Dockerfile & Colab notebook

---

## ğŸ§ª How to Cite

If you use this repo, please cite:

```bibtex
@software{lesion_forecasting_2025,
  author  = {Vishnu Vardhan Pingali},
  title   = {Forecasting Skin Lesion Progression with Swin-UNet + CBAM and PatchGAN},
  year    = {2025},
  url     = {https://github.com/yourname/skin-forecasting}
}
```

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ see `LICENSE` for details.

---

## ğŸ™ Acknowledgements

* Swinâ€‘UNet, CBAM, PatchGAN, and VGG19 implementations inspired by their original papers and openâ€‘source repos.
* Thanks to the openâ€‘source community for datasets, tooling, and feedback.

---

## ğŸ¤ Contributing

Contributions are welcome! Please open an issue or PR with a clear description, steps to reproduce, and screenshots of qualitative results.
